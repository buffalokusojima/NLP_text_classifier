{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word_listからtfidf値を元に圧縮したリストを作成して保存するプログラム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 必要なライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import os,sys\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定数宣言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '.'\n",
    "DATA_PATH = '/text'\n",
    "TF_IDF_NUM = 0.1\n",
    "OUTPUT_PATH = '/tf-idf-'+str(TF_IDF_NUM)\n",
    "DICTIONARY_PATH = '/Dictionary'\n",
    "DICTIONARY_NAME = '/tf-idf-'+str(TF_IDF_NUM)+\"-dictionary.txt\"\n",
    "WORD_LIST = 'word_list.pkl'\n",
    "TFIDF_VECTOR = 'tfidf_vectorizer.pkl'\n",
    "TFIDF_RESULT = 'tfidf_result.pkl'\n",
    "TFIDF_WORD_LIST = '/tfidf_word_list.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存していたword_listを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "movie-enter {'text': ['ジョニデ', 'バートン', '監督', '贈る', 'ファミリー', 'インパクト', '大', 'キャラクター', 'ビジュアル', '注目', 'バートン', '監督', 'デップ', '最強', 'コンビ', '贈る', '世界', '待望', '大作', '5', '月', '19', '日', '公開', 'キャラクタービジュアル', '公開', 'する', 'れる', '公開', '記念', 'する', 'コスプレコンテスト', '実施', '決定', 'する', '本', '作', '魔女', 'ヴァンパイア', 'する', 'れる', 'しまう', 'バーナバス・コリンズ', '物語', 'ヴァンパイア', 'なる', 'バーナバス', '生き埋め', 'する', 'れる', 'しまう', '目覚める', 'の', '2', '世紀', '後', '1972', '年', '没落', 'する', '家', '末裔', '出会う', 'バーナバス', '父親', '唯一', '財産', '家族', '言葉', '胸', '魔女', '手', '家族', '守る', '一族', '繁栄', '取り戻す', 'する', '1966', '年', '1971', '年', 'ABC', 'テレビ', '放送', 'する', 'れる', '人気', 'ドラマ', 'ベース', '映画', '化', 'する', '作品', '主人公', '1752', '年', '移民', 'する', '裕福', '家', '育つ', 'プレイボーイ', 'バーナバス・コリンズ', '日', '彼', '魔女', 'アンジェリーク', '死', '運命', 'なる', 'ヴァンパイア', 'する', 'れる', '生き埋め', 'する', 'れる', 'しまう', '2', '世紀', '後', '1972', '年', '予期', 'する', 'きっかけ', '自分', '墓', '開放', 'する', 'れる', '劇的', '変化', '遂げる', '世の中', 'バーナバス', '不可思議', '謎', '秘める', '家', '末裔', '姿', '描く', '父親', '唯一', '財産', '家族', '言葉', '胸', '魔女', '手', '家族', '守る', '没落', 'する', '一族', '繁栄', '取り戻せる', 'こと', 'できる', 'の', '主人公', 'バーナバス', '演じる', 'の', 'カメレオン', '俳優', 'いう', 'れる', 'その他', '魔女', 'アンジェリーク', '役', '007', 'エヴァ・グリーン', '家', '当主', '役', 'ミシェル・ファイファー', '一家', '同居', 'する', '医師', '役', 'ヘレナ・ボナム', '演じる', '怠惰', '兄弟', '役', '息子', 'デイビッド', '役', 'ヒューゴ', '不思議', '発明', 'デイビッド・コリンズ', '家', 'ひねくれる', '気味', '長女', 'キャロリン', '役', 'クロエ・モレッツ', '演じる', '人気', '急上昇', '俳優', '実力', '派', '俳優', '勢揃い', 'する', 'いる', '今回', '豪華', 'キャスト', '演じる', 'キャラクタービジュアル', '公開', 'する', 'れる', '70', '年代', '風', 'ポップ', 'カラー', '彩る', 'れる', 'インパクト', '大', '仕上がり', '見る', '忘れる', 'られる', 'ビジュアル', '4', '月', '下旬', '全国', '主要', '劇場', '交通', '広告', '登場', 'する', '予定', 'キャラクタービジュアル', '一覧', 'ENTER', '来日', 'する', 'ジョニデ', 'バートン', '監督', '会える', 'プレミア', 'レッド', 'カーペット', '招待', 'する', 'プレゼント', '掲載', 'する', 'いる', '1', '彼ら', '会える', '方法', 'ある', 'それ', '今回', '開催', '決定', 'する', 'コスプレコンテスト', '募集', 'テーマ', '2', '本', '作', '登場', 'キャラクター', 'デップ', '演じる', 'バーナバス・コリンズ', 'エヴァ・グリーン', '演じる', '魔女', 'アンジェリーク', 'する', 'こと', '入賞', '者', '来日', 'する', 'ジョニデ', 'バートン', '監督', '登壇', '予定', '5', '月', '12', '日', '土', 'TOHO', 'シネマズ', '行う', 'れる', 'プレミア', '招待', 'する', 'れる', 'ほか', '受賞', 'する', 'イベント', '華やか', 'レッド', 'カーペット', '歩く', 'こと', 'できる', 'プラチナ', '特典', 'つく', 'くる', '2', '目', 'これ', '数々', '名作', '作り上げる', 'くる', 'ジョニデ', 'バートン', '監督', '作品', 'チャーリー', 'チョコレート', '工場', 'スウィーニー・トッドフリード', '街', '悪魔', '理髪', '店', '登場', 'する', 'キャラクター', '募集', 'こちら', '入賞', '者', '本', '作', 'プレミア', 'チケット', '贈呈', 'する', 'れる', 'どちら', '募集', '締め切り', '5', '月', '7', '日', '月', '詳細', '公式', 'サイト', 'チェック', 'する', '映画', '5', '月', '19', '日', '土', 'ルーブル', 'ほか', '全国', 'ロードショー', '映画', '-', '作品', '情報', '映画', '-', '公式', 'サイト', '関連', '記事', 'PR', 'ため', '緊急', '来日', '決定', 'ジョニデ', '常識', 'はずれ', 'ヴァンパイア', '予告', '映像', '注目', 'ヴァンパイア', '誕生', 'ジョニデ', '主演', '公開', '日', '決定', 'バートン', 'ジョニデ', '8', '度目', 'タッグ', '念', 'バンパイア', '役', '演じる'], 'file': 'movie-enter-6499995'}\n"
     ]
    }
   ],
   "source": [
    "word_list = []\n",
    "tfidf_vector_list = []\n",
    "tfidf_result_list = []\n",
    "for path in glob.glob(ROOT_DIR+ROOT_DIR+DATA_PATH+\"/*/*.pkl\", recursive=True):\n",
    "    if path.split(\"/\")[-1] == WORD_LIST:\n",
    "        with open(path, \"rb\") as f:\n",
    "            words = pickle.load(f)\n",
    "            word_list.append({'label': path.split(\"/\")[-2], 'words': words})\n",
    "    elif path.split(\"/\")[-1] == TFIDF_VECTOR:\n",
    "        with open(path, \"rb\") as f:\n",
    "            tfidf = pickle.load(f)\n",
    "            tfidf_vector_list.append({'label': path.split(\"/\")[-2], 'tfidf': tfidf})\n",
    "    elif path.split(\"/\")[-1] == TFIDF_RESULT:\n",
    "        with open(path, \"rb\") as f:\n",
    "            tfidf = pickle.load(f)\n",
    "            tfidf_result_list.append({'label': path.split(\"/\")[-2], 'tfidf': tfidf})\n",
    "    \n",
    "print(len(word_list))\n",
    "print(word_list[0]['label'], word_list[0]['words'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文章内のTFIDFの基準値以下の単語を削除した文章に変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie-enter\n",
      "it-life-hack\n",
      "kaden-channel\n",
      "topic-news\n",
      "livedoor-homme\n",
      "peachy\n",
      "sports-watch\n",
      "dokujo-tsushin\n",
      "smax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "if not os.path.isdir(ROOT_DIR+OUTPUT_PATH):\n",
    "    os.mkdir(ROOT_DIR+OUTPUT_PATH)\n",
    "\n",
    "for i,words in enumerate(word_list):\n",
    "    vector = tfidf_vector_list[i]['tfidf']\n",
    "    feature_names = vector.get_feature_names()\n",
    "    #words_tfidf = tfidf_vector_list[i]['tfidf'].transform([\" \".join(words['words'][0]['text'])])\n",
    "\n",
    "    for text in words['words']:\n",
    "        tfidf_word_list = []\n",
    "        \n",
    "        words_tfidf = vector.transform([\" \".join(text['text'])])\n",
    "    \n",
    "        for txt in text['text']:\n",
    "            try:\n",
    "                index = feature_names.index(txt)\n",
    "            except:\n",
    "                pass\n",
    "            tfidf_num = words_tfidf.toarray()[0][index]\n",
    "            if tfidf_num > TF_IDF_NUM:\n",
    "                tfidf_word_list.append(txt)\n",
    "        if tfidf_word_list:\n",
    "            text['text'] = tfidf_word_list\n",
    "    words['words'] = [word for word in words['words'] if word['text']]\n",
    "    if not os.path.isdir(ROOT_DIR+OUTPUT_PATH+\"/\"+words['label']):\n",
    "        os.mkdir(ROOT_DIR+OUTPUT_PATH+\"/\"+words['label'])\n",
    "    with open(ROOT_DIR+OUTPUT_PATH+\"/\"+words['label']+TFIDF_WORD_LIST, \"wb\") as f:\n",
    "        pickle.dump(words['words'], f)\n",
    "    print(words['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word_listの中身を見てみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['ニート', 'レイ', 'ブル', '変更', '効果', '呼称', 'レイ', 'ブル', '呼称', '変更', 'ある', 'レイ', 'ブル', '払しょく', '呼称', '変更', '策', '効果', 'ある', '効果', '回答', '3', '万', '1149', '票', '回答', '者', '効果', 'ある', '回答', '728', '票', 'レイ', 'ブル', '遅咲き', 'ある', 'ある', 'ニート', '呼称', 'レイ', 'ブル', '変更', '効果'], 'file': 'kaden-channel-6223393'}\n"
     ]
    }
   ],
   "source": [
    "print(word_list[2]['words'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF値で圧縮したリストから辞書を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = []\n",
    "for words in word_list:\n",
    "    for word in words['words']:\n",
    "        dictionary.append(word['text'])\n",
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 辞書の中身をみてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(28387 unique tokens: ['8', 'する', 'れる', 'アンジェリーク', 'インパクト']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不要な単語削除してないからだろうが辞書デカ過ぎ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(232 unique tokens: ['8', 'れる', '作', '姿', '家']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary.filter_extremes(no_below = 100, no_above = 0.2)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary.filter_extremes(no_below = 200, no_above = 0.2)\n",
    "dictionary.save_as_text(ROOT_DIR+ROOT_DIR+DICTIONARY_PATH+DICTIONARY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
